clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
clust = cutree(clusters, k = 4)
data$cluster = clusters
clust = cutree(clusters, k = 4)
data$cluster = clusters
plot(clust)
clust = cutree(clusters, k = 4)
plot(clust, labels = rownames(data))
plot(clusters, labels = rownames(data))
clust = cutree(clusters, k = 4)
plot(clust, labels = rownames(data))
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3)
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 1:10
wss_values = sapply(ks, wss)
plot(k.values, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
?clusGap
#Gap statistic
library(cluster)
gap_stat = clusGap(data, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
?clusGap
plot(gap_stat, main = "Gap Statistic for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 1:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(i in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 1:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(i in seq_along(ks))
{
wss_values[i] = wss(ks[i])
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores = avgSilMean(k)
}
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(data, distance)
mean(sil[,3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores = avgSilMean(k)
}
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[,3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores = avgSilMean(k)
}
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[,3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores = avgSilMean(k)
}
ks = 2:10
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[,3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores = avgSilMean(k)
}
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores = avgSilMean(k)
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores[i] = avgSilMean(k)
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores[k] = avgSilMean(k)
}
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
data = mtcars
dist_matrix = dist(data, method = "euclidean")
clusters = hclust(dist_matrix, method = "centroid")
plot(clusters, labels = rownames(data))
rect.hclust(clusters, k = 3, border = c("red","green","blue"))
#Elbow plot
wss = function(k)
{
kmeans(data, centers = k, nstart = 10)$tot.withinss
}
ks = 2:10
wss_values = matrix(NA, ncol = 1, nrow = 10)
for(k in seq_along(ks))
{
wss_values[i] = wss(k)
}
wss_values = sapply(ks, wss)
plot(ks, wss_values, type = "b", pch = 19,
xlab = "Number of clusters K",
ylab = "Total within-clusters sum of squares",
main = "Elbow Plot for Determining Optimal Clusters")
#Gap statistic
library(cluster)
gap_stat = clusGap(data, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
plot(gap_stat, main = "Gap Statistic for Determining Optimal Clusters")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores[k] = avgSilMean(k)
}
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 10)
for(k in seq_along(ks))
{
silScores[k] = avgSilMean(k)
}
ks = 2:10
#Gap statistic
library(cluster)
gap_stat = clusGap(data, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
plot(gap_stat, main = "Gap Statistic for Determining Optimal Clusters")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 9)
for(i in 1:9)
{
silScores[i] = avgSilMean(ks[i])
}
plot(ks, silScores, type = "b", pch = 20,
xlab = "Number of clusters K",
ylab = "Average silhouette width")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 9)
for(i in 1:9)
{
silScores[i] = avgSilMean(ks[i])
}
plot(ks, silScores, type = "b", pch = 20,
xlab = "Number of clusters K",
ylab = "Average silhouette width")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 9)
for(i in 1:9)
{
silScores[i] = avgSilMean(ks[i])
}
plot(ks, silScores, type = "b", pch = 20,
xlab = "Number of clusters K",
ylab = "Average silhouette width")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 9)
for(i in 1:9)
{
silScores[i] = avgSilMean(ks[i])
}
plot(ks, silScores, type = "b", pch = 20,
xlab = "Number of clusters K",
ylab = "Average silhouette width")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 9)
for(i in 1:9)
{
silScores[i] = avgSilMean(ks[i])
}
plot(ks, silScores, type = "b", pch = 20,
xlab = "Number of clusters K",
ylab = "Average silhouette width")
distance = dist(data, method = "euclidean")
avgSilMean = function(k)
{
km = kmeans(data, centers = k, nstart = 10)
sil = silhouette(km$cluster, distance)
mean(sil[, 3])
}
silScores = matrix(NA, 1, 9)
for(i in 1:9)
{
silScores[i] = avgSilMean(ks[i])
}
plot(ks, silScores, type = "b", pch = 20,
xlab = "Number of clusters K",
ylab = "Average silhouette width")
pwr.anova.test(k = 3, f = 0.1, sig.level = 0.05, power = 0.8)
library(pwr)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.1, sig.level = 0.05, power = 0.8)
library(pwr)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.5, sig.level = 0.05, power = 0.8)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.3, sig.level = 0.05, power = 0.8)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.3, sig.level = 0.05, power = 0.8)
library(pwr)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.2, sig.level = 0.05, power = 0.8)
library(pwr)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.5, sig.level = 0.05, power = 0.8)
library(pwr)
# Perform power analysis
pwr.anova.test(k = 3, f = 0.4, sig.level = 0.05, power = 0.8)
setwd("C:/UnityProjects/neural_networks")
validationResults = read.csv("validation_results.csv")
View(validationResults)
validationResults = read.csv("validation_results.csv")
actualOutput = validatinResults$Actual.Output
validationResults = read.csv("validation_results.csv")
actualOutput = validatinResults[2]
confusionMatrix = table(Actual = actualOutput, Predicted = predictedOutput)
validationResults = read.csv("validation_results.csv")
actualOutput = validationResults$Actual.Output
predictedOutput = validationResults$Model.Output
confusionMatrix = table(Actual = actualOutput, Predicted = predictedOutput)
print(confusionMatrix)
validationResults = read.csv("validation_results.csv")
actualOutput = validationResults$Actual.Output
predictedOutput = validationResults$Model.Output
confusionMatrix = table(Actual = actualOutput, Predicted = predictedOutput)
print(confusionMatrix)
testingResults = read.csv("testing_results.csv")
actualOutput = testingResults$Actual.Output
predictedOutput = testingResults$Model.Output
confusionMatrix = table(Actual = actualOutput, Predicted = predictedOutput)
print(confusionMatrix)
correct_predictions <- sum(diag(confusionMatrix))
total_predictions <- sum(confusionMatrix)
accuracy = correct_predictions / total_predictions
